{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk9_bfVXmXzj"
      },
      "source": [
        "## Grid-Search\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nUZjUtEbbd_s",
        "outputId": "2b177182-b112-4a65-d0f6-de2983c23651"
      },
      "outputs": [],
      "source": [
        "# Source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n",
        "# GridSearch\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1797, 64)\n",
            "(1797,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Loading the Digits dataset\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# To apply an classifier on this data, we need to flatten the image, to\n",
        "# turn the data in a (samples, feature) matrix:\n",
        "n_samples = len(digits.images)\n",
        "X = digits.images.reshape((n_samples, -1))\n",
        "y = digits.target\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Split the dataset in two equal parts\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.5, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Tuning hyper-parameters for precision\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters set found on train set:\n",
            "\n",
            "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "\n",
            "Grid scores on train set:\n",
            "\n",
            "0.986 (+/-0.016) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.959 (+/-0.028) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.988 (+/-0.017) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.982 (+/-0.026) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.988 (+/-0.017) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.983 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.988 (+/-0.017) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.983 (+/-0.026) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.974 (+/-0.012) for {'C': 1, 'kernel': 'linear'}\n",
            "0.974 (+/-0.012) for {'C': 10, 'kernel': 'linear'}\n",
            "0.974 (+/-0.012) for {'C': 100, 'kernel': 'linear'}\n",
            "0.974 (+/-0.012) for {'C': 1000, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report on test-set:\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        89\n",
            "           1       0.97      1.00      0.98        90\n",
            "           2       0.99      0.98      0.98        92\n",
            "           3       1.00      0.99      0.99        93\n",
            "           4       1.00      1.00      1.00        76\n",
            "           5       0.99      0.98      0.99       108\n",
            "           6       0.99      1.00      0.99        89\n",
            "           7       0.99      1.00      0.99        78\n",
            "           8       1.00      0.98      0.99        92\n",
            "           9       0.99      0.99      0.99        92\n",
            "\n",
            "    accuracy                           0.99       899\n",
            "   macro avg       0.99      0.99      0.99       899\n",
            "weighted avg       0.99      0.99      0.99       899\n",
            "\n",
            "\n",
            "# Tuning hyper-parameters for recall\n",
            "\n",
            "Best parameters set found on train set:\n",
            "\n",
            "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "\n",
            "Grid scores on train set:\n",
            "\n",
            "0.986 (+/-0.019) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.957 (+/-0.028) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.987 (+/-0.019) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.981 (+/-0.028) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.987 (+/-0.019) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.982 (+/-0.026) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.987 (+/-0.019) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.982 (+/-0.026) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.971 (+/-0.010) for {'C': 1, 'kernel': 'linear'}\n",
            "0.971 (+/-0.010) for {'C': 10, 'kernel': 'linear'}\n",
            "0.971 (+/-0.010) for {'C': 100, 'kernel': 'linear'}\n",
            "0.971 (+/-0.010) for {'C': 1000, 'kernel': 'linear'}\n",
            "\n",
            "Detailed classification report on test-set:\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        89\n",
            "           1       0.97      1.00      0.98        90\n",
            "           2       0.99      0.98      0.98        92\n",
            "           3       1.00      0.99      0.99        93\n",
            "           4       1.00      1.00      1.00        76\n",
            "           5       0.99      0.98      0.99       108\n",
            "           6       0.99      1.00      0.99        89\n",
            "           7       0.99      1.00      0.99        78\n",
            "           8       1.00      0.98      0.99        92\n",
            "           9       0.99      0.99      0.99        92\n",
            "\n",
            "    accuracy                           0.99       899\n",
            "   macro avg       0.99      0.99      0.99       899\n",
            "weighted avg       0.99      0.99      0.99       899\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set the parameters by cross-validation\n",
        "tuned_parameters = [{'kernel': ['rbf'], \n",
        "                     'gamma': [1e-3, 1e-4],\n",
        "                     'C': [1, 10, 100, 1000]},\n",
        "                    \n",
        "                    {'kernel': ['linear'], \n",
        "                     'C': [1, 10, 100, 1000]}]\n",
        "\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(\n",
        "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on train set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on train set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report on test-set:\")\n",
        "    print()\n",
        "    #print(\"The model is trained on the full development set.\")\n",
        "    #print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()\n",
        "\n",
        "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
        "# output model is the same for precision and recall with ties in quality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptIc2k2WmgOK"
      },
      "source": [
        "## Random-Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "qKTpBmlkci0o",
        "outputId": "ee92a6a1-81d8-420c-86eb-bbabb47a4551"
      },
      "outputs": [],
      "source": [
        "# RandomSearch CV\n",
        "# Source: https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from time import time\n",
        "import scipy.stats as stats\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.linear_model import SGDClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# get some data\n",
        "X, y = load_digits(return_X_y=True, n_class=3)\n",
        "\n",
        "# build a classifier\n",
        "clf = SGDClassifier(loss='hinge', penalty='elasticnet',\n",
        "                    fit_intercept=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Utility function to report best scores\n",
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
        "                  .format(results['mean_test_score'][candidate],\n",
        "                          results['std_test_score'][candidate]))\n",
        "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
        "            print(\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomizedSearchCV took 1.29 seconds for 15 candidates parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.989 (std: 0.014)\n",
            "Parameters: {'alpha': 0.0006913806210326083, 'average': False, 'l1_ratio': 0.11043256340099361}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.989 (std: 0.007)\n",
            "Parameters: {'alpha': 0.00012948402484271382, 'average': False, 'l1_ratio': 0.8849478512947113}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.987 (std: 0.014)\n",
            "Parameters: {'alpha': 0.0014703603391795646, 'average': True, 'l1_ratio': 0.8497527615968151}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# specify parameters and distributions to sample from\n",
        "param_dist = {'average': [True, False],\n",
        "              'l1_ratio': stats.uniform(0, 1),\n",
        "              'alpha': stats.loguniform(1e-4, 1e0)}\n",
        "\n",
        "# run randomized search\n",
        "n_iter_search = 15\n",
        "random_search = RandomizedSearchCV(clf, \n",
        "                                   param_distributions=param_dist,\n",
        "                                   n_iter=n_iter_search)\n",
        "\n",
        "start = time()\n",
        "random_search.fit(X, y)\n",
        "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
        "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
        "report(random_search.cv_results_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GridSearchCV took 6.68 seconds for 100 candidate parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.994 (std: 0.005)\n",
            "Parameters: {'alpha': 0.001, 'average': False, 'l1_ratio': 0.4444444444444444}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.993 (std: 0.009)\n",
            "Parameters: {'alpha': 1.0, 'average': False, 'l1_ratio': 0.0}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.993 (std: 0.011)\n",
            "Parameters: {'alpha': 0.001, 'average': False, 'l1_ratio': 0.1111111111111111}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# use a full grid over all parameters\n",
        "param_grid = {'average': [True, False],\n",
        "              'l1_ratio': np.linspace(0, 1, num=10),\n",
        "              'alpha': np.power(10, np.arange(-4, 1, dtype=float))}\n",
        "\n",
        "# run grid search\n",
        "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
        "start = time()\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
        "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
        "report(grid_search.cv_results_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i876dSrZml3Z"
      },
      "source": [
        "## Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YkGvqHemcldf"
      },
      "outputs": [],
      "source": [
        "#HyperOPT: Bayesian Optimization\n",
        "\n",
        "#Refer: https://hyperopt.github.io/hyperopt-sklearn/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "tk1USHp-8xgG",
        "outputId": "62b132a9-1235-4656-cb15-75e971995d19"
      },
      "outputs": [],
      "source": [
        "#!pip install hpsklearn\n",
        "#!pip install hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "uIuCxbYtJhZW",
        "outputId": "1f57fd1d-a775-4cf2-fdab-7294aa4cb377"
      },
      "outputs": [],
      "source": [
        "from hpsklearn import HyperoptEstimator, any_classifier\n",
        "from sklearn.datasets import fetch_openml\n",
        "from hyperopt import tpe\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import check_random_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Download the data and split into training and test sets\n",
        "digits = fetch_openml('mnist_784', parser='auto', as_frame=False)\n",
        "\n",
        "X = digits.data\n",
        "y = digits.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "random_state = check_random_state(0)\n",
        "permutation = random_state.permutation(X.shape[0])\n",
        "X = X[permutation]\n",
        "y = y[permutation]\n",
        "X = X.reshape((X.shape[0], -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Split the dataset in two equal parts\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['0', '4', '1', ..., '7', '1', '1'], dtype=object)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "estim = HyperoptEstimator( classifier=any_classifier('clf'),  \n",
        "                          algo=tpe.suggest, \n",
        "                          trial_timeout=300)\n",
        "\n",
        "#estim.fit( X_train, y_train )\n",
        "\n",
        "#print( estim.score( X_test, y_test ) )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print( estim.best_model() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "LIVE: Hyper-param tuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
